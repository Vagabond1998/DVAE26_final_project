{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TosejOqVMiD9"
   },
   "source": [
    "## Introduction\n",
    "Image classification is a technique in the field of computer vision that classifies images into pre-defined categories. The machine learning model looks for specific features in an image such as wheels, edges,..and use these learned features to categorise the object in the image. Once the model is trained on large datasets of images,  and learns the features, it can predict the category of new images.\n",
    "Image classification is used in many diverse applications such as:\n",
    "1. Object detection\n",
    "2. Medical image analysis\n",
    "3. Image search engines\n",
    "4. Facial recognition\n",
    "\n",
    "In this lab, we will classify *CIFAR-10* images data. The *CIFAR-10* dataset consists of 60000 32x32 colour images, 50000 are training images and 10000 are test images. Then, we will integrate our model to *weights and biases* MLOPS platform to add experiments' tracking to the machine learning pipeline.\n",
    "\n",
    "*Weights and biases* plaform provides developers with lighweight tools to quickly track their machine learning training experiments, evaluate model performance, reproduce models, and visualize results in the form of regressions. It also has functions to share findings with the team mates.\n",
    "\n",
    "\n",
    "## Objectives\n",
    "The main objectives of this Jupyter notebook are:\n",
    "\n",
    "* To learn how to build a classification application using Keras library.\n",
    "* To learn how to integrate the classification application to *weights and biases* MLOPS platform.\n",
    "* To observe and analyze the visualization and results of a machine learning experiment.\n",
    "\n",
    "\n",
    "## Tools and Libraries\n",
    "For this Jupyter notebook, we will need the following tools and libraries:\n",
    "\n",
    "1. Python 3.x\n",
    "2. Access to colab by Google\n",
    "3. Tensorflow deep learning library\n",
    "4. Keras library to construct neural network algorithm\n",
    "4. Numpy library for mathematical operations\n",
    "5. Matplotlib library for data visualization\n",
    "\n",
    "## Data\n",
    "We will be using the *CIFAR-10* dataset. This dataset contains 60000 coloured images from 10 different categories ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'). Read more about this dataset here https://www.cs.toronto.edu/~kriz/cifar.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WlBgwkwwH_p"
   },
   "source": [
    "# Part - I Image classification using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibHdIhhkaD-s"
   },
   "source": [
    "## 1. Importing Libraries\n",
    "Let's start by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dnHCnlk01xPx",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m absolute_import, division, print_function\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras import Sequential\n",
    "from keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ylXQiSpaMDV"
   },
   "source": [
    "## 2. Loading the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJuOUR8EaFm7"
   },
   "source": [
    "Load the dataset using keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clhBSD4216CG",
    "outputId": "40acb86f-ab74-451f-cdb4-641cbb7e2210"
   },
   "outputs": [],
   "source": [
    "cifar10 = cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRBHsOLKg_gF"
   },
   "source": [
    "Define an array of the existing classes in CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXBA3DxD2L0J"
   },
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCb4rn9qaklW"
   },
   "source": [
    "## 3. Data Exploration and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIITe-e4a3tR"
   },
   "source": [
    "#### Checking unique values per class in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GK38k5eg2sIr",
    "outputId": "a0384faa-b474-4e87-ae5d-74ac39f69752"
   },
   "outputs": [],
   "source": [
    "print('train set dimensions ', train_images.shape)\n",
    "print('train set labels', train_labels) #Each Label is between 0-9\n",
    "print('-------------------')\n",
    "print('test set dimensions',test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_XmM1R-2wFd",
    "outputId": "24fadc3e-5f6f-4b78-d572-a915da7895d6"
   },
   "outputs": [],
   "source": [
    "print ('Unique classes in the CIFAR-10 train set', np. unique(train_labels))\n",
    "print ('Frequency of unique classes in CIFAR-10 train set', np. unique(train_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-nrBlfPs3Q8B",
    "outputId": "d1aa6fa3-1b0a-4f08-931a-e65b0fa84e33"
   },
   "outputs": [],
   "source": [
    "print ('Unique classes in the CIFAR-10 test set', np. unique(test_labels))\n",
    "print ('Frequency of unique classes in CIFAR-10 test set', np. unique(test_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDRQB3YAa-u0"
   },
   "source": [
    "#### Plotting sample image from train set\n",
    "Inspect the first image in the train set, you will notice that the pixel values fall in the range of 0 to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "juA_-oc74DmW",
    "outputId": "6e2b8187-185e-42cc-edd2-8ef46e0dc83d"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nx5cb0wEil8S"
   },
   "source": [
    "Scaling the images between 0–1 to feed it into the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDV0po8u4csx"
   },
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "PLoGQOLF4oAS",
    "outputId": "305abb38-ad1e-4d85-854f-f7c8356c5c52"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0zQGGybbQXI"
   },
   "source": [
    "## 5. Neural Network building & application\n",
    "Now that we have understood the data, we can build a simple neural network to classify the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PnrW3do43Cs"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Dense(128, activation=tf.nn.relu),\n",
    "    Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uU2Bgoyg7Fvd"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VgJNH_d77KNu",
    "outputId": "962c4265-a772-4bef-8fef-ded8a77f8068"
   },
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_wr9Xyn8TVh",
    "outputId": "30f46742-2de0-4614-f322-f270d2c7526a"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mJezPzRJ8USv",
    "outputId": "72134e0a-5dfc-4ce3-9eae-0e0e54601543"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vk0KnybL7NkC",
    "outputId": "b165a5b0-b1f4-4477-9e39-f481d080eddf"
   },
   "outputs": [],
   "source": [
    "print ('The position of the highest prability of all classes ',np.argmax(predictions[0]))\n",
    "print ('The model is confident it is a ', class_names[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ti96hGEFoVid"
   },
   "source": [
    "Lets compare the predicted label by the model with the true label of the image in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EP_xQ7n-9XPz",
    "outputId": "29e447a2-77af-4b26-d41e-ac8c28bdb37f"
   },
   "outputs": [],
   "source": [
    "print ('The true label of the image is', test_labels[0])\n",
    "print ('The image is actually an', class_names[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9E5e6HGNqLdV"
   },
   "source": [
    "Lets compare the `predicted_label` with the `true_label` of the first image in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "yKx2bI5W9bDQ",
    "outputId": "12784b33-a2c4-4257-ff77-08d0a292ee9a"
   },
   "outputs": [],
   "source": [
    "def plot_image(position, predictions, true_label, dataset):\n",
    "  predictions, true_label, image = predictions[position], true_label[position], dataset[position]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.imshow(image, cmap=plt.cm.binary)\n",
    "  predicted_label = np.argmax(predictions)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'orange'\n",
    "  plt.xlabel(\"{} {:2.0f}% - {}\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions),\n",
    "                               np.array(class_names)[true_label.astype(int)]),\n",
    "                                color=color)\n",
    "position = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plot_image(position, predictions, test_labels, test_images)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVbyHYPkwWsw"
   },
   "source": [
    "# Part - II Image classification using Keras integrated with weights and biases (MLOPS platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H572AVLFJ3VA"
   },
   "source": [
    "## Connect your code to weights and biases (wandb)\n",
    "Step-by-step guide to installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWWoGYMLZ64T"
   },
   "source": [
    "## 1. Installl w&b library\n",
    "Start by installing the library and logging in to your free account. If this is your first time logging to wandb or you are not logged in, the link that appears after `wandb.login()` will take you to sign-up/login page so you can create an account.\n",
    "If you're prompted to authenticate yourself, you need to copy the key from your w&b profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dE2TbJCoeRAO"
   },
   "source": [
    "First, install the python library to interact with the Weights and Biases API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0SbCCccqilow",
    "outputId": "c7287bce-5961-449a-ca5e-85553610908a"
   },
   "outputs": [],
   "source": [
    "#!pip install -qU wandb\n",
    "import os\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"Lab3.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNVGso6HeWzS"
   },
   "source": [
    "First time users, login and provide your API key when prompted. Copy the key by double-clicking on it in the pop-up page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "Og-VeYyNixNc",
    "outputId": "5ece813f-9e36-4c4e-df16-1fb04f291667"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint, WandbEvalCallback\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "print('Now you are connected to W&B and you will be able to visualize your project runs there')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_It8BPoviKBr"
   },
   "source": [
    "## 2. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OevTb22QiRas"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGUWoCRmidlQ"
   },
   "source": [
    "## 3. Loading the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIgN1vIWjkXQ",
    "outputId": "3aa83b4c-117c-4476-f1ab-b9e47030e891"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train, x_test = x_train[::5] / 255., x_test / 255.\n",
    "y_train = y_train[::5]\n",
    "\n",
    "CLASS_NAMES = [\"airplane\", \"automobile\", \"bird\", \"cat\",\n",
    "               \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "\n",
    "print('Shape of x_train: ', x_train.shape)\n",
    "print('Shape of y_train: ', y_train.shape)\n",
    "print('Shape of x_test: ', x_test.shape)\n",
    "print('Shape of y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20r1FyQJj3Uh"
   },
   "source": [
    "## 4. Neural Network Development & Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qW0dt2IMnrgQ"
   },
   "source": [
    "Build the Neural Network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0tfuuQgCj3tv"
   },
   "outputs": [],
   "source": [
    "def Model():\n",
    "  inputs = keras.layers.Input(shape=(32, 32, 3))\n",
    "\n",
    "  x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "  x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n",
    "  x = keras.layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "  x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n",
    "  x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n",
    "\n",
    "  x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "  x = keras.layers.Dense(128, activation='relu')(x)\n",
    "  x = keras.layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "  outputs = keras.layers.Dense(len(CLASS_NAMES), activation='softmax')(x)\n",
    "\n",
    "  return keras.models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sK1AvFW8nmEL"
   },
   "source": [
    "Initialize the hyperparameters and metadata using `wandb.init()`. Initialise the model parameters in `wandb.config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "id": "ARpFuucknEzs",
    "outputId": "2028a6d3-b8fa-4efd-f6bc-8c15241e7bda"
   },
   "outputs": [],
   "source": [
    "run = wandb.init(project='image classification project',\n",
    "                 config={\n",
    "                     \"learning_rate\": 0.005,\n",
    "                     \"epochs\": 5,\n",
    "                     \"batch_size\": 1024,\n",
    "                     \"loss_function\": \"sparse_categorical_crossentropy\",\n",
    "                     \"architecture\": \"CNN\",\n",
    "                     \"dataset\": \"CIFAR-10\"\n",
    "                 })\n",
    "config = wandb.config\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = Model()\n",
    "model.summary()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(config.learning_rate)\n",
    "model.compile(optimizer, config.loss_function, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M713NRVjoYuF"
   },
   "source": [
    "Add WandbMetricsLogger to log metrics and WandbModelCheckpoint to log model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seHqebVFoJaH",
    "outputId": "8ab8ae4b-e9b1-4288-8970-511d8256ba80"
   },
   "outputs": [],
   "source": [
    "wandb_callbacks = [\n",
    "    WandbMetricsLogger(),\n",
    "    WandbModelCheckpoint(\n",
    "    filepath=\"my_model_{epoch:02d}.keras\",\n",
    "    monitor=\"val_loss\",  # or another metric you wish to monitor\n",
    "    verbose=1,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=\"epoch\",\n",
    "    initial_value_threshold=None\n",
    "),\n",
    "]\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=config.epochs,\n",
    "          batch_size=config.batch_size,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=wandb_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgb8TbxSor8i"
   },
   "source": [
    "Use wandb.log for custom metrics. In this example we log the error rate in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384,
     "referenced_widgets": [
      "de06c82478004ec084e7284de92fd0cb",
      "41b1eba5bbba4759ae1df64aa7b03f2b",
      "e38bf2c474a54cf48bfdbe9fcaaaa5d8",
      "268a8e7128a84442a0917ae9e30ac785",
      "743c89b4dcc246e6a48373114d7a3fb3",
      "84af36190c22455d9b760afaef10624e",
      "af79ce64380d42979e4d82dc1e7d839e",
      "b096d21a50174f4d9b4e0fadebb4eabb"
     ]
    },
    "id": "okvu4Nj4ol5j",
    "outputId": "959dfe9a-407f-4456-92e7-43f8c0df1842"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test Error Rate: ', round((1 - accuracy) * 100, 2))\n",
    "\n",
    "wandb.log({'Test Error Rate': round((1 - accuracy) * 100, 2)})\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore wandb embedded tools\n",
    "\n",
    "**Purpose:** Utilize the tools provided by wandb for in-depth analysis, result sharing, and documentation.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Log in to your wandb profile, navigate to the project, and select the latest run.\n",
    "\n",
    "2. Review the visualizations available in the workspace tab to understand the performance of the model.\n",
    "\n",
    "3. Use the  `Create Report` tool on the most recent run's page to generate a report, including charts, system panels, and epochs panels.\n",
    "\n",
    "4. Examine the results displayed in the regression charts, and analyze the findings within the report.\n",
    "\n",
    "5. Test the options of `Smoothing` and `ignore outliers` in the Runs tab and write a brief analysis."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (DVAE26-TF)",
   "language": "python",
   "name": "dvae26-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "268a8e7128a84442a0917ae9e30ac785": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41b1eba5bbba4759ae1df64aa7b03f2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_743c89b4dcc246e6a48373114d7a3fb3",
      "placeholder": "​",
      "style": "IPY_MODEL_84af36190c22455d9b760afaef10624e",
      "value": "2.387 MB of 2.387 MB uploaded\r"
     }
    },
    "743c89b4dcc246e6a48373114d7a3fb3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84af36190c22455d9b760afaef10624e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af79ce64380d42979e4d82dc1e7d839e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b096d21a50174f4d9b4e0fadebb4eabb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "de06c82478004ec084e7284de92fd0cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_41b1eba5bbba4759ae1df64aa7b03f2b",
       "IPY_MODEL_e38bf2c474a54cf48bfdbe9fcaaaa5d8"
      ],
      "layout": "IPY_MODEL_268a8e7128a84442a0917ae9e30ac785"
     }
    },
    "e38bf2c474a54cf48bfdbe9fcaaaa5d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af79ce64380d42979e4d82dc1e7d839e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b096d21a50174f4d9b4e0fadebb4eabb",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
