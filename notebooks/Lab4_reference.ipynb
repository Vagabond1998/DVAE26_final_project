{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c314461-8500-41e7-90ed-5be7dc21d3e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font color='navy'> \n",
    "    \n",
    "# MLflow Recipes for Data Preprocessing and Model Training  \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5973347e-3962-41f8-a0a6-3cd3f4db0730",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Machine learning (ML) projects often involve various data preprocessing steps and model training phases. In this lab, we will demonstrate how to use MLflow Recipes to streamline and automate these processes. MLflow Recipes provide a convenient way to define and execute reusable steps for data ingestion, preprocessing, model training, and more. We will apply MLflow Recipes to the Customer Churn dataset, exploring data preprocessing techniques and training machine learning models for churn prediction.\n",
    "\n",
    "\n",
    "\n",
    "## Objectives\n",
    "The main objectives of this lab are:\n",
    "\n",
    "1. To introduce the concept of MLflow Recipes for automating machine learning workflows.\n",
    "2. To demonstrate how to use MLflow Recipes to define and execute data preprocessing and model training steps.\n",
    "3. To compare and evaluate the performance of different machine learning models for income prediction.\n",
    "\n",
    "\n",
    "## Tools and Libraries\n",
    "For this lab, we will use the following tools and libraries:\n",
    "\n",
    "1. Python 3.x\n",
    "2. Jupyter Notebook\n",
    "3. Pandas library for data manipulation and analysis\n",
    "4. Numpy library for mathematical operations\n",
    "5. Scikit-learn library for machine learning algorithms\n",
    "6. Matplotlib library for data visualization\n",
    "7. Seaborn library for data visualization\n",
    "8. MLflow for managing machine learning experiments and pipelines\n",
    "\n",
    "## Data\n",
    "We will use the Customer Churn dataset for this lab. This dataset contains information about customers, including attributes like customer age, contract duration, and monthly charges. The goal is to predict whether a customer will churn (leave) or not based on these attributes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc73ab5-8e2f-4068-94f6-6fbf26e55a57",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries and Loading Data\n",
    "Let's start by importing the necessary libraries and loading the Diabetes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e5dc97e-4f5e-468a-8c28-74406c333dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install mlflow\n",
    "#! pip install \"flaml[automl]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d5cddef-a7da-4a46-8388-be9b396308c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "from mlflow.recipes import Recipe\n",
    "import mlflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a1dc6-d899-40e5-ab1b-79b96fe04f6a",
   "metadata": {},
   "source": [
    "## 2. Load MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b043e2fd-851f-4d8a-85c2-a2390fc8f315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load MLflow\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d80032a-aeba-414c-a52b-0650385feca3",
   "metadata": {},
   "source": [
    "## 3. Creating MLflow pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6273b87-5eed-45d8-bb65-2531f1ae6457",
   "metadata": {},
   "source": [
    "#### 3.1 Defining the steps\n",
    "Create an MLflow Recipe and define the steps for data preprocessing and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84c1bfa4-d9e7-4612-a1e0-4ad6e5c58e69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarla/.conda/envs/DVAE26/lib/python3.10/site-packages/mlflow/recipes/recipe.py:399: FutureWarning: MLflow Recipes is deprecated and will be removed in MLflow 3.0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Failed to find recipe.yaml!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create an MLflow Recipe\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mRecipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Clean the recipe\u001b[39;00m\n\u001b[1;32m      5\u001b[0m r\u001b[38;5;241m.\u001b[39mclean()\n",
      "File \u001b[0;32m~/.conda/envs/DVAE26/lib/python3.10/site-packages/mlflow/recipes/recipe.py:409\u001b[0m, in \u001b[0;36mRecipe.__new__\u001b[0;34m(cls, profile)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m profile:\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA profile name must be provided to construct a valid Recipe object.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    406\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m    407\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m recipe_root_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_recipe_root_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m recipe_root_path:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    412\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    413\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecipe directory path cannot contain spaces. Please move or rename your \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m    417\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/DVAE26/lib/python3.10/site-packages/mlflow/recipes/utils/__init__.py:121\u001b[0m, in \u001b[0;36mget_recipe_root_path\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m     curr_dir_path \u001b[38;5;241m=\u001b[39m curr_dir_path\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# If curr_dir_path == curr_dir_path.parent,\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# we have reached the root directory without finding\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# the desired recipe.yaml file\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_RECIPE_CONFIG_FILE_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mMlflowException\u001b[0m: Failed to find recipe.yaml!"
     ]
    }
   ],
   "source": [
    "# Create an MLflow Recipe\n",
    "r = Recipe(profile=\"local\")\n",
    "\n",
    "# Clean the recipe\n",
    "r.clean()\n",
    "\n",
    "# Inspect the recipe\n",
    "r.inspect()\n",
    "\n",
    "# Run the 'ingest' step\n",
    "r.run(\"ingest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c83830-376c-48e3-be83-c781c1d07d5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.2 Exploratory Data Analysis\n",
    "Perform some basic Exploratory Data Analysis (EDA) on the ingested dataset. This step includes visualizing data distributions and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43766ff-f5a6-4bf4-97a8-7604d22e086b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform some basic EDA on the ingested dataset\n",
    "ingested_data = r.get_artifact(\"ingested_data\")\n",
    "# Iterate through columns for EDA\n",
    "for col in ingested_data.columns:\n",
    "    if col == \"Churn\":  # Exclude the target variable\n",
    "        continue\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if ingested_data[col].dtype == \"object\":  # Check if the column is non-numeric\n",
    "        sns.countplot(data=ingested_data, x=col)\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.xticks(rotation=45)  # Rotate x-axis labels for readability\n",
    "    else:\n",
    "        sns.boxplot(data=ingested_data, x=\"Churn?\", y=ingested_data[col])\n",
    "        plt.title(f'Distribution of {col} by Churn')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97ab7ba-4dae-43c8-a098-3e0de32fdccb",
   "metadata": {},
   "source": [
    "#### 3.3 Data Splitting\n",
    "Run the 'split' step to split the data into training and testing sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ff01d-f683-4316-aafc-957e7d9a8603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the 'split' step\n",
    "r.run(\"split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57e926-48db-450d-8fe4-9a64b083e3c1",
   "metadata": {},
   "source": [
    "#### 3.4 Data Transformation\n",
    "Run the 'transform' step for data transformation and feature scaling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf7fe5-10bf-4158-8584-dc43b78968be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the 'transform' step\n",
    "r.run(\"transform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd945a6-e0c3-4d45-b7ae-a57b1d284f77",
   "metadata": {},
   "source": [
    "#### 3.5 Data Training\n",
    "Run the 'train' step to train machine learning models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee95b3-e737-4695-a46b-844482b6196d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Run the 'train' step\n",
    "r.run(\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c892911-f348-4582-b570-1f2d273d52ab",
   "metadata": {},
   "source": [
    "#### 3.6 Model Evaluation\n",
    "Evaluate the trained models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38473948-6e70-44f0-8774-ee3594d52790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r.run(\"evaluate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a7365-2506-43e4-82c4-b285feb14bc0",
   "metadata": {},
   "source": [
    "#### 3.6 Model Registry\n",
    "Register and store the trained models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd650a8-c275-4549-a0b3-4f56f440f9ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r.run(\"register\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda8a48a-3aac-4777-a23e-c1ebbce65e1b",
   "metadata": {},
   "source": [
    "## Task 1: ML Models Performance Comparison\n",
    "\n",
    "**Purpose:** Compare the performance of multiple machine learning models for churn prediction.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. In the `3.5 Data Training` section, modify `train.py` to train classifiers other than Random Forests. For instance, consider using models like Logistic Regression.\n",
    "2. After training the additional models, conduct a thorough evaluation of their performance on the test dataset.\n",
    "3. Compare the performance of each machine learning model run. Ensure you have recorded the run ID for each model.\n",
    "4. Provide explanatory comments to explain the significance of model comparison and highlight any insights derived from the evaluation.\n",
    "5. Conclude by discussing which model appears to be the most suitable for the churn prediction task based on the evaluation results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b838b4c3-c03c-4473-9a7c-c256408dd212",
   "metadata": {},
   "source": [
    "Logistic regression is unsuitable due to extremely low recall (0.148) and F1 score (0.25) indicating failure to identify churners.\n",
    "Random Forest is the most suitable model, as it demonstrates superior performance on metrics critical for imbalanced classification, particularly recall (0.475), F1 score (0.617), and precision-recall AUC (0.756)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9adde4-2b7c-4bb8-8fc4-31718e346227",
   "metadata": {},
   "source": [
    "## Task 2: Automated Model Selection with automl/flaml\n",
    "\n",
    "\n",
    "**Purpose:** Utilize the FLAML (Fast, Lightweight, and Multi-Layered) library for automated model selection.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Install flaml Python library using the command:  `pip install \"flaml[automl]\"`.\n",
    "2. Configure FLAML to perform automated machine learning tasks, including hyperparameter tuning, algorithm selection, and model evaluation. Hint: you need to modify the `recipe.yaml` file.\n",
    "3. Discuss the benefits and limitations of using automated model selection with FLAML in comparison to manual model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b453dd6-dde0-464b-8e98-b99c249a6b0a",
   "metadata": {},
   "source": [
    "In comparison to manual model selection, FLAML offers speed, systematic exploration, and strong baseline performance, but at the cost of reduced interpretability, lower transparency, and reliance on correct metric and validation design. In this assignment, FLAML's selection of an ExtraTreees model demonstrate its effectiveness for tabular, imbalanced classification tasks, while manual model selection remains valuable for interpretabilityu and domain-driven modeling decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DVAE26",
   "language": "python",
   "name": "dvae26"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
