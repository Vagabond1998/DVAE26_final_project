{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af4657e2-4f90-4622-8d4a-6596b5472d39",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Sentiment analysis is the process of analyzing digital texts to determine the emotional tone. The emotional tone of a text could be positive, negative, or neutral.\n",
    "\n",
    "In this lab, we will learn how to analyze text data according to sentiment. Then, we will integrate our model to *Hugging face* platform which is a popular MLOPs platform that helps users build, deploy and train machine learning models.\n",
    "\n",
    "*Hugging face* provides developers with lighweight tools to smoothely track their machine learning training experiments, evaluate the model performance, reproduce models, and visualize results. The platform supports team work and shared projects as well. \n",
    "\n",
    "\n",
    "## Objectives\n",
    "The main objectives of this Jupyter notebook are:\n",
    "\n",
    "* To learn how to build a sentiment analysis classification application using pytorch library.\n",
    "* To observe and analyze the visualizations and results of a machine learning experiment.\n",
    "* To learn how to integrate the sentiment analysis application with Hugging face platform.\n",
    "\n",
    "\n",
    "## Tools and Libraries\n",
    "For this Jupyter notebook, we will need the following tools and libraries:\n",
    "\n",
    "1. Python 3.x\n",
    "2. Pytorch deep learning library\n",
    "3. transformers\n",
    "\n",
    "## What is?\n",
    "* Transformers. Transformers are a kind of neural network architecture that is commonly used have in the field of natural language processing (NLP). Key features of transformers include attention Mechanism, parallel processing, scalability. Popular examples of transformers are BERT and GPT.\n",
    "* Pytorch. PyTorch is an open source ML library developed by the AI Research lab at Facebook. the library is used mostly for computer vision and natural language processing applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b3d665-4c54-42b1-8e13-d2047e8c1d96",
   "metadata": {},
   "source": [
    "## Step 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905492c-cdce-48ec-89b9-41c81d828006",
   "metadata": {},
   "source": [
    "First, you need to install the necessary libraries to run the Lab activity.\n",
    "1) A transformer is a deep learning architecture, initially proposed in 2017. It has been significantly adopted for training large language models on large (language) datasets.\n",
    "2) Torch PyTorch is a Python-based scientific computing package used to implement neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f57d19e0-cf4f-4595-afd6-7f6a936a795b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da67e783-dec0-43f7-b391-86ed034547a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8274415c-05e9-48f1-8171-04194d7d53c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c8d435d-7314-47a7-9da6-b927bf4b6545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 21:05:03.295677: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-22 21:05:05.800504: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01064144-6baa-42f0-9ddc-118038885b17",
   "metadata": {},
   "source": [
    "## Step 2. Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e230d9-4ed1-431a-ace4-35dad8bef5a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_name= \"distilbert-base-uncased-finetuned-sst-2-english\" #even if you don't define a model name, by deafult this model is used.\n",
    "classifier = pipeline (\"sentiment-analysis\", model=model_name) #Pipelines in the Hugging Face Transformers library provide a user-friendly and effecient way to deploy ML models for various tasks.\n",
    "                                                               #Pipeline(..,..) takes the 'task' the user wants to perform for example \"sentiment-analysis\" and the 'model' to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2051d2b6-dd82-4d6d-a0e4-c398b2a57638",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted sentiment of text_1 is [{'label': 'POSITIVE', 'score': 0.9986727237701416}]\n",
      "The predicted sentiment of text_2 is [{'label': 'NEGATIVE', 'score': 0.994065523147583}]\n",
      "The predicted sentiment of text_3 is [{'label': 'POSITIVE', 'score': 0.9982800483703613}]\n"
     ]
    }
   ],
   "source": [
    "text_1 = classifier(\"The weather today is nice. It is dark, cloudy and expected to snow in the evening.\")\n",
    "text_2 = classifier(\"It is dark, cloudy and expected to snow in the evening.\")\n",
    "text_3 = classifier(\"We are not sure wether we like the AI Engineering course or not, but it is an important course.\")\n",
    "print(f'The predicted sentiment of text_1 is {text_1}')\n",
    "print(f'The predicted sentiment of text_2 is {text_2}')\n",
    "print(f'The predicted sentiment of text_3 is {text_3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f697bc-a30f-4249-8cf8-c8636a00c509",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'POSITIVE', 'score': 0.9986727237701416}\n",
      "{'label': 'NEGATIVE', 'score': 0.8883466720581055}\n"
     ]
    }
   ],
   "source": [
    "#Try another way to read the text\n",
    "\n",
    "results = classifier([\"The weather today is nice. It is dark, cloudy and expected to snow in the evening.\", \"I hope you don't hate this weather.\"])\n",
    "for r in results:\n",
    "    print (r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc51c9-1ac3-49e5-a253-5a9de4c2cb2b",
   "metadata": {},
   "source": [
    "## Step 3. Using a Tokinizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9af247-ecb4-4562-abe4-a5cc6febdd74",
   "metadata": {},
   "source": [
    "A tokenizer is used in natural language processing (NLP) to breakdown the text into smaller units (tokens) which could be words or characters so they are processed by a machine learning model. Multiple steps are included in tokenization, we mention:<br>\n",
    "* Tokenization: Splitting text into tokens.\n",
    "* Indexing: Assigning unique numerical IDs to tokens. The main reason behind assigning IDs to tokens is that neural networks work with numerical respresentations only. Another advantage for IDs assignment is the consistancy of mapping tokens into IDs which ensures that the same text is always represented in the same way, resulting in consistent learning of models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6258452-4643-4898-a179-312297b0a087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model= AutoModelForSequenceClassification.from_pretrained(model_name) #used to load a pre-trained model\n",
    "tokenizer =AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df87add8-8cc5-49d8-b453-999a5afd73e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tokens: ['i', 'hope', 'you', 'don', \"'\", 't', 'hate', 'the', 'cold', 'dark', 'weather', '.']\n",
      "\n",
      " Token IDs: [1045, 3246, 2017, 2123, 1005, 1056, 5223, 1996, 3147, 2601, 4633, 1012]. Each token is assigned a unique ID, a numerical representation of which the ML model understands\n",
      "\n",
      " Input IDs passed to the ML model: {'input_ids': [101, 1045, 3246, 2017, 2123, 1005, 1056, 5223, 2023, 4633, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}. \n",
      " The IDs 101 and 102 represent the beginning and the ending of a string\n"
     ]
    }
   ],
   "source": [
    "#Pass the text to the tokenizer and observe the results\n",
    "\n",
    "tokens=tokenizer.tokenize(\"I hope you don't hate the cold dark weather.\")\n",
    "print (f' Tokens: {tokens}\\n')\n",
    "token_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
    "print (f' Token IDs: {token_ids}. Each token is assigned a unique ID, a numerical representation of which the ML model understands\\n')\n",
    "input_ids=tokenizer(\"I hope you don't hate this weather.\")\n",
    "print (f' Input IDs passed to the ML model: {input_ids}. \\n The IDs 101 and 102 represent the beginning and the ending of a string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a0b690c-5e0c-4417-907c-b3b88e166ece",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'POSITIVE', 'score': 0.9986727237701416}\n",
      "{'label': 'NEGATIVE', 'score': 0.7226830720901489}\n"
     ]
    }
   ],
   "source": [
    "#Observe the output after passing a tokenizer to the pipeline.\n",
    "\n",
    "classifier = pipeline (\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "results = classifier([\"The weather today is nice. It is dark, cloudy and expected to snow in the evening.\", \"I hope you don't hate the cold dark weather.\"])\n",
    "for r in results:\n",
    "    print (r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f94ffbca-4684-46af-80d7-a9a8e9a2e66e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = [\"The weather today is nice. It is dark, cloudy and expected to snow in the evening.\", \"I hope you don't hate the cold dark weather.\"]\n",
    "batch = tokenizer(X_train, padding =True, truncation=True, max_length=512, return_tensors=\"pt\") #pt as pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83306e21-0646-4f3b-a5c0-fa3bc7738a64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1996,  4633,  2651,  2003,  3835,  1012,  2009,  2003,  2601,\n",
      "          1010, 24706,  1998,  3517,  2000,  4586,  1999,  1996,  3944,  1012,\n",
      "           102],\n",
      "        [  101,  1045,  3246,  2017,  2123,  1005,  1056,  5223,  1996,  3147,\n",
      "          2601,  4633,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e007711-bc19-4b76-b8e3-c38649a8b8e6",
   "metadata": {},
   "source": [
    "## Step 4.1 Wrapping in Well Structured Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24d03491-a27a-444a-929a-e510e5477b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = next(model.parameters()).device  \n",
    "#def get_sentiment(text):\n",
    "#    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "#    outputs = model(**inputs)\n",
    "#    return \"positive\" if torch.argmax(outputs.logits) == 1 else \"negative\"\n",
    "\n",
    "def get_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # <-- critical fix\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    pred = outputs.logits.argmax(dim=-1).item()\n",
    "    return \"positive\" if pred == 1 else \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a06c8ccd-140a-4712-955b-c6b4c9e3a8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "print(get_sentiment(\"I love learning new things!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce96557e-b1c1-4b86-86cd-d07e6f5d63a9",
   "metadata": {},
   "source": [
    "## Step 4.2 Write `analyze_file()` function\n",
    "\n",
    "Analyze_file() takes file_path as input, tokenizes and predicts the sentiment of the input text using the trained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6438c06d-ea71-4752-8086-888d84553990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_file(file_path):\n",
    "    lines = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    pos_to_neg = 0\n",
    "    for l in lines:\n",
    "        if get_sentiment(l) == \"positive\":\n",
    "            pos_to_neg += 1\n",
    "        else:\n",
    "            pos_to_neg -= 1\n",
    "    if pos_to_neg >= 0:\n",
    "        return \"Overall Sentiment: Positive\"\n",
    "    else:\n",
    "        return \"Overall Sentiment: Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c72cff97-c170-4a84-a703-b823f81eb28c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_sentiment.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_sentiment.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43manalyze_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m, in \u001b[0;36manalyze_file\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21manalyze_file\u001b[39m(file_path):\n\u001b[1;32m      2\u001b[0m     lines \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m         lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m      5\u001b[0m     pos_to_neg \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/DVAE26/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_sentiment.txt'"
     ]
    }
   ],
   "source": [
    "file_path = 'test_sentiment.txt'\n",
    "analyze_file(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7fa779-4af8-4ed6-9ea4-7ac7f1738f7e",
   "metadata": {},
   "source": [
    "## Step 5: Save the Model Locally (This is important for versioning and reusability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fd323e-93dc-4787-a81f-f2ef6f8f93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"sentiment_model_testing\"\n",
    "model.save_pretrained(model_save_path) #Specifies the path to save all files.\n",
    "tokenizer.save_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf0770-d1b1-48f6-9d5e-853ba13f44eb",
   "metadata": {},
   "source": [
    "## Step 6: Setup Account on Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b34aae-2376-45a4-a42f-a0c1c597e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install huggingface_hub\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n",
    "#checkout git\n",
    "#login to huggingface, setting, access token, generate a new token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ccf7db-772e-4bd6-b938-6e3ead790dfa",
   "metadata": {},
   "source": [
    "## Step 7: Upload the Model to Hugging Face\n",
    "\n",
    "Uploading the model from your local directory to Hugging Face is important to make the model publicly available for others to download and use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e4bc4d-0d20-42ca-8656-1e29e367428e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import Repository\n",
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "\n",
    "repo_id = \"Vagabond98/dvae26-lab5-test\"\n",
    "\n",
    "api.create_repo(repo_id=repo_id, exist_ok=True, private=False)\n",
    "model.push_to_hub(repo_id)\n",
    "tokenizer.push_to_hub(repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82022c-2d68-46e3-accb-fa2b55d965af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DVAE26",
   "language": "python",
   "name": "dvae26"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
